{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image \n",
    "import numpy as np \n",
    "import os \n",
    "import time\n",
    "import matplotlib.pyplot as plt  \n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import models,transforms,datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_exams import *\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline \n",
    "\n",
    "def show_grid(tensor):\n",
    "    tensor = tensor.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    \n",
    "    # code added here\n",
    "    tensor = std*tensor + mean \n",
    "\n",
    "    # The next two lines are required to maintain the image values between 0 and 1\n",
    "    tensor[tensor > 1] = 1 \n",
    "    tensor[tensor < 0] = 0\n",
    "    plt.figure(figsize = (20,2))    \n",
    "    \n",
    "    # code added here\n",
    "    plt.imshow(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "composed_transforms = transforms.Compose([transforms.Resize(256),transforms.CenterCrop(224),\n",
    "                                          transforms.ToTensor(), normalize])\n",
    "\n",
    "data_dir = 'data_exam'\n",
    "dataset = {x: datasets.ImageFolder(os.path.join(data_dir, x), composed_transforms)\n",
    "         for x in ['train', 'valid']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_shuffle(x):\n",
    "    if x == 'train':\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "dataset_loader = {x: torch.utils.data.DataLoader(dataset[x], batch_size=4,\n",
    "                                               shuffle=to_shuffle(x), num_workers=6)\n",
    "                for x in ['train', 'valid']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, classes = next(iter(dataset_loader['train']))\n",
    "n_images = 4\n",
    "out = torchvision.utils.make_grid(inputs[0:n_images])\n",
    "\n",
    "show_grid(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.categories = 1000 #Number of ImageNet categories\n",
    "        #Insert your code here\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 3, out_channels = 64, kernel_size = 3, padding = 1),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3, padding = 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
    "        )\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = 3, padding = 1),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Conv2d(in_channels = 128, out_channels = 128, kernel_size = 3, padding = 1),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
    "        )\n",
    "        self.block3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size = 3, padding = 1),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size = 3, padding = 1),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size = 3, padding = 1),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
    "        )\n",
    "        self.block4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 256, out_channels = 512, kernel_size = 3, padding = 1),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, padding = 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, padding = 1),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
    "        )\n",
    "        self.block5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, padding = 1),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, padding = 1),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, padding = 1),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
    "        )\n",
    "        self.classify = nn.Sequential(\n",
    "            nn.Linear(in_features = 512 * 7 * 7, out_features = 4096),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(in_features = 4096, out_features = 4096),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(in_features = 4096, out_features = self.categories),\n",
    "            nn.Softmax()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #Insert your code here\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = self.block5(x)\n",
    "        x = x.view(x.size(0), -1) #Transformation before the classify layer.\n",
    "        # Insert your code here\n",
    "        x = self.classify(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mynet = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import model_zoo\n",
    "# Insert your code here\n",
    "params_pre = model_zoo.load_url('https://download.pytorch.org/models/vgg16-397923af.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_module_2 import *\n",
    "# Insert your code here \n",
    "give_params_to_model(mynet, params_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in mynet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "mynet.classify._modules['6'] = nn.Linear(in_features = 4096, out_features = 2)\n",
    "mynet.classify._modules['7'] = nn.Softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "optimizer_mynet = torch.optim.SGD(mynet.classify[6].parameters(),\n",
    "                                  lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer_exam(model,dataloader, num_epochs,optimizer=None,train=True):\n",
    "\n",
    "    r\"\"\"\n",
    "    Implements a generic training function that can be used for training a network as well as for evaluating\n",
    "    performance on a validation set\n",
    "\n",
    "    Args:\n",
    "        model: Network to be trained (or evaluated). Could be the complete network or a single layer of it\n",
    "        dataloader: iterator over the dataset\n",
    "        epochs (int, optional): number of epochs for training (default: 1)\n",
    "        optimizer: Optimizer used for the training. Usually a torch.optim object\n",
    "        train (bool, optional): Run the function in train or eval mode (default: True)\n",
    "    \"\"\"\n",
    "    sizes = {'train': 257.0, 'valid': 140}\n",
    "    if train:\n",
    "        model.train()\n",
    "        phase='train'\n",
    "    else:\n",
    "        model.eval()\n",
    "        phase='valid'\n",
    "    print(\"Phase is {}\".format(phase))\n",
    "    for epoch in range(num_epochs):\n",
    "        total = 0\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        batch_counter = 1\n",
    "        for inputs,classes in dataloader[phase]:\n",
    "#             inputs , classes = Variable(torch.from_numpy(inputs)),Variable(torch.from_numpy(classes))\n",
    "            outputs = model(inputs)\n",
    "            loss_function = nn.CrossEntropyLoss()\n",
    "            loss = loss_function(outputs,classes)\n",
    "            optimizer = optimizer\n",
    "            optimizer.zero_grad()\n",
    "            if train:\n",
    "                if optimizer is None:\n",
    "                    raise ValueError('Pass optimizer for train mode')\n",
    "#                 optimizer = optimizer\n",
    "#                 optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            _,preds = torch.max(outputs.data,1)\n",
    "\n",
    "            running_loss += loss.data.item()\n",
    "            running_corrects += torch.sum(preds == classes.data)\n",
    "\n",
    "            print(\"Cumulated loss of the \" + str(batch_counter) + \" first batches: {}\".format(running_loss))\n",
    "            batch_counter += 1\n",
    "            #depending on py version\n",
    "        epoch_loss = float(running_loss)\n",
    "        epoch_acc = float(running_corrects)/sizes[phase]\n",
    "        print('Loss: {:}, Acc: {:}'.format(epoch_loss, epoch_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_exam(model=mynet,\n",
    "             dataloader=dataset_loader, \n",
    "             num_epochs=10,\n",
    "             optimizer=optimizer_mynet,\n",
    "             train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_exam(model=mynet,\n",
    "             dataloader=dataset_loader, \n",
    "             num_epochs=1,\n",
    "             optimizer=optimizer_mynet,\n",
    "             train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
